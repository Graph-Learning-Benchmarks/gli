{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cora Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.sparse as sparse\n",
    "from dgl.data import CoraGraphDataset\n",
    "\n",
    "dataset = CoraGraphDataset()\n",
    "graph = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the data file in only one file `cora.npz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10556, 2)\n"
     ]
    }
   ],
   "source": [
    "# node features\n",
    "node_feats = sparse.csr_matrix(graph.ndata[\"feat\"].numpy())\n",
    "# node labels\n",
    "node_class = graph.ndata[\"label\"].numpy()  # (2708,)\n",
    "# edge list\n",
    "edge = torch.stack(graph.edges()).numpy().T\n",
    "print(edge.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw text for cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinhuang/opt/miniconda3/envs/arxiv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'abs', 'label'])\n",
      "title ['Title: The megaprior heuristic for discovering protein sequence patterns  ']\n",
      "abs ['Abstract: Several computer algorithms for discovering patterns in groups of protein sequences are in use that are based on fitting the parameters of a statistical model to a group of related sequences. These include hidden Markov model (HMM) algorithms for multiple sequence alignment, and the MEME and Gibbs sampler algorithms for discovering motifs. These algorithms are sometimes prone to producing models that are incorrect because two or more patterns have been combined. The statistical model produced in this situation is a convex combination (weighted average) of two or more different models. This paper presents a solution to the problem of convex combinations in the form of a heuristic based on using extremely low variance Dirichlet mixture priors as part of the statistical model. This heuristic, which we call the megaprior heuristic, increases the strength (i.e., decreases the variance) of the prior in proportion to the size of the sequence dataset. This causes each column in the final model to strongly resemble the mean of a single component of the prior, regardless of the size of the dataset. We describe the cause of the convex combination problem, analyze it mathematically, motivate and describe the implementation of the megaprior heuristic, and show how it can effectively eliminate the problem of convex combinations in protein sequence pattern discovery. ']\n",
      "label ['Neural Networks']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from gli.raw_text_utils import load_data\n",
    "\n",
    "_, raw_text_dict = load_data(dataset=\"cora\", use_text=True)\n",
    "\n",
    "print(raw_text_dict.keys())\n",
    "\n",
    "for key, item in raw_text_dict.items():\n",
    "    print(key, item[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gli.io import save_graph, Attribute\n",
    "\n",
    "node_attrs = [\n",
    "    Attribute(\n",
    "        \"NodeFeature\",\n",
    "        node_feats,\n",
    "        \"Node features of Cora dataset, 1/0-valued vectors.\",\n",
    "        \"int\",\n",
    "        \"SparseTensor\",\n",
    "    ),\n",
    "    Attribute(\n",
    "        \"NodeLabel\",\n",
    "        node_class,\n",
    "        \"Node labels of Cora dataset, int ranged from 1 to 7.\",\n",
    "        \"int\",\n",
    "        \"Tensor\",\n",
    "    ),\n",
    "    Attribute(\n",
    "        \"NodeRawTextTitle\",\n",
    "        raw_text_dict[\"title\"],\n",
    "        \"Raw text of title of each node in Cora dataset, list of strings.\",\n",
    "        \"str\",\n",
    "        \"List[str]\"\n",
    "    ),\n",
    "    Attribute(\n",
    "        \"NodeRawTextAbstract\",\n",
    "        raw_text_dict[\"abs\"],\n",
    "        \"Raw text of abstract of each node in Cora dataset, list of strings.\",\n",
    "        \"str\",\n",
    "        \"List[str]\"\n",
    "    ),\n",
    "    Attribute(\n",
    "        \"NodeRawTextLabel\",\n",
    "        raw_text_dict[\"label\"],\n",
    "        \"Raw text of label of each node in Cora dataset, list of strings.\",\n",
    "        \"str\",\n",
    "        \"List[str]\"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "metadata = save_graph(\n",
    "    name=\"cora\",\n",
    "    edge=edge,\n",
    "    num_nodes=graph.num_nodes(),\n",
    "    node_attrs=node_attrs,\n",
    "    description=\"CORA dataset.\",\n",
    "    cite=\n",
    "    \"@inproceedings{yang2016revisiting,\\ntitle={Revisiting semi-supervised learning with graph embeddings},\\nauthor={Yang, Zhilin and Cohen, William and Salakhudinov, Ruslan},\\nbooktitle={International conference on machine learning},\\npages={40--48},\\nyear={2016},\\norganization={PMLR}\\n}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata.json and graph data (.npz files) is now saved in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"CORA dataset.\",\n",
      "  \"data\": {\n",
      "    \"Node\": {\n",
      "      \"NodeFeature\": {\n",
      "        \"description\": \"Node features of Cora dataset, 1/0-valued vectors.\",\n",
      "        \"type\": \"int\",\n",
      "        \"format\": \"SparseTensor\",\n",
      "        \"file\": \"cora__graph__Node_NodeFeature__7032c9c380d1889061dcbbcd76b8c427.sparse.npz\"\n",
      "      },\n",
      "      \"NodeLabel\": {\n",
      "        \"description\": \"Node labels of Cora dataset, int ranged from 1 to 7.\",\n",
      "        \"type\": \"int\",\n",
      "        \"format\": \"Tensor\",\n",
      "        \"file\": \"cora__graph__6c912909fa18eff10797210ea5e485fe.npz\",\n",
      "        \"key\": \"Node_NodeLabel\"\n",
      "      },\n",
      "      \"NodeRawTextTitle\": {\n",
      "        \"description\": \"Raw text of title of each node in Cora dataset, list of strings.\",\n",
      "        \"type\": \"str\",\n",
      "        \"format\": \"List[str]\",\n",
      "        \"optional file\": \"cora__graph__Node_NodeRawTextTitle__4a9ad6575f5acfe3b828fe66f072bd5c.optional.npz\",\n",
      "        \"key\": \"Node_NodeRawTextTitle\"\n",
      "      },\n",
      "      \"NodeRawTextAbstract\": {\n",
      "        \"description\": \"Raw text of abstract of each node in Cora dataset, list of strings.\",\n",
      "        \"type\": \"str\",\n",
      "        \"format\": \"List[str]\",\n",
      "        \"optional file\": \"cora__graph__Node_NodeRawTextAbstract__d0e5436087314624c74a9f040d6f394f.optional.npz\",\n",
      "        \"key\": \"Node_NodeRawTextAbstract\"\n",
      "      },\n",
      "      \"NodeRawTextLabel\": {\n",
      "        \"description\": \"Raw text of label of each node in Cora dataset, list of strings.\",\n",
      "        \"type\": \"str\",\n",
      "        \"format\": \"List[str]\",\n",
      "        \"optional file\": \"cora__graph__Node_NodeRawTextLabel__06d184316789acc0902db2b8c1472f95.optional.npz\",\n",
      "        \"key\": \"Node_NodeRawTextLabel\"\n",
      "      }\n",
      "    },\n",
      "    \"Edge\": {\n",
      "      \"_Edge\": {\n",
      "        \"file\": \"cora__graph__6c912909fa18eff10797210ea5e485fe.npz\",\n",
      "        \"key\": \"Edge_Edge\"\n",
      "      }\n",
      "    },\n",
      "    \"Graph\": {\n",
      "      \"_NodeList\": {\n",
      "        \"file\": \"cora__graph__Graph_NodeList__23bbef862fd6037395412eb03b4e1d9c.sparse.npz\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"citation\": \"@inproceedings{yang2016revisiting,\\ntitle={Revisiting semi-supervised learning with graph embeddings},\\nauthor={Yang, Zhilin and Cohen, William and Salakhudinov, Ruslan},\\nbooktitle={International conference on machine learning},\\npages={40--48},\\nyear={2016},\\norganization={PMLR}\\n}\",\n",
      "  \"is_heterogeneous\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print metadata\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = graph.ndata[\"train_mask\"].nonzero().squeeze().numpy()\n",
    "val_set = graph.ndata[\"val_mask\"].nonzero().squeeze().numpy()\n",
    "test_set = graph.ndata[\"test_mask\"].nonzero().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gli.io import save_task_node_classification\n",
    "\n",
    "task_data = save_task_node_classification(\n",
    "    name=\"cora\",\n",
    "    description=\"Node classification on CORA dataset. Planetoid split.\",\n",
    "    feature=[\"Node/NodeFeature\"],\n",
    "    target=\"Node/NodeLabel\",\n",
    "    num_classes=7,\n",
    "    train_set=train_set,\n",
    "    val_set=val_set,\n",
    "    test_set=test_set,\n",
    "    task_id=\"1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task data (.json and .npz files) is now saved in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"Node classification on CORA dataset. Planetoid split.\",\n",
      "  \"type\": \"NodeClassification\",\n",
      "  \"feature\": [\n",
      "    \"Node/NodeFeature\"\n",
      "  ],\n",
      "  \"target\": \"Node/NodeLabel\",\n",
      "  \"num_classes\": 7,\n",
      "  \"train_set\": {\n",
      "    \"file\": \"cora__task_node_classification_1__41e167258678b585872679839ce9c40f.npz\",\n",
      "    \"key\": \"train_set\"\n",
      "  },\n",
      "  \"val_set\": {\n",
      "    \"file\": \"cora__task_node_classification_1__41e167258678b585872679839ce9c40f.npz\",\n",
      "    \"key\": \"val_set\"\n",
      "  },\n",
      "  \"test_set\": {\n",
      "    \"file\": \"cora__task_node_classification_1__41e167258678b585872679839ce9c40f.npz\",\n",
      "    \"key\": \"test_set\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(task_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORA dataset.\n",
      "Node classification on CORA dataset. Planetoid split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinhuang/Documents/research/gli/datasets/cora/../../gli/utils.py:262: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343673238/work/aten/src/ATen/SparseCsrTensorImpl.cpp:56.)\n",
      "  return torch.sparse_csr_tensor(crow_indices,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=10556,\n",
       "      ndata_schemes={'NodeFeature': Scheme(shape=(1433,), dtype=torch.float32), 'NodeLabel': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gli.dataloading import read_gli_graph, read_gli_task, combine_graph_and_task\n",
    "\n",
    "g = read_gli_graph(\"./metadata.json\")\n",
    "t = read_gli_task(\"./task_node_classification_1.json\")\n",
    "data = combine_graph_and_task(g, t)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data with raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data files already exist. Skip downloading.\n",
      "CORA dataset.\n",
      "All data files already exist. Skip downloading.\n",
      "Node classification on CORA dataset. Planetoid split.\n",
      "Graph(num_nodes=2708, num_edges=10556,\n",
      "      ndata_schemes={'NodeFeature': Scheme(shape=(1433,), dtype=torch.float32), 'NodeLabel': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "from gli.dataloading import get_gli_dataset\n",
    "\n",
    "dataset = get_gli_dataset(\"cora\", \"NodeClassification\", load_raw_text=True, verbose=True)\n",
    "\n",
    "data = dataset[0]\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw text are saved in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Title: The megaprior heuristic for discovering protein sequence patterns  ',\n",
       " 'Abstract: Several computer algorithms for discovering patterns in groups of protein sequences are in use that are based on fitting the parameters of a statistical model to a group of related sequences. These include hidden Markov model (HMM) algorithms for multiple sequence alignment, and the MEME and Gibbs sampler algorithms for discovering motifs. These algorithms are sometimes prone to producing models that are incorrect because two or more patterns have been combined. The statistical model produced in this situation is a convex combination (weighted average) of two or more different models. This paper presents a solution to the problem of convex combinations in the form of a heuristic based on using extremely low variance Dirichlet mixture priors as part of the statistical model. This heuristic, which we call the megaprior heuristic, increases the strength (i.e., decreases the variance) of the prior in proportion to the size of the sequence dataset. This causes each column in the final model to strongly resemble the mean of a single component of the prior, regardless of the size of the dataset. We describe the cause of the convex combination problem, analyze it mathematically, motivate and describe the implementation of the megaprior heuristic, and show how it can effectively eliminate the problem of convex combinations in protein sequence pattern discovery. ',\n",
       " 'Neural Networks')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.NodeRawTextTitle[0], data.NodeRawTextAbstract[0], data.NodeRawTextLabel[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding LICENSE and README.md, the dataset directory will be the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gli')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d44b81210f2b1cc6f5cbf794116c1ed3b756872db4baf49235947e0f03609f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
