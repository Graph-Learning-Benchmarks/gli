{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/GLI/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This notebook is adapted from https://github.com/graphdeeplearning/benchmarking-gnns/blob/master/data/superpixels/prepare_superpixels_CIFAR.ipynb\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading..\n",
      "Archive:  superpixels.zip\n",
      " extracting: ./data/superpixels/cifar10_150sp_test.pkl  \n",
      " extracting: ./data/superpixels/cifar10_150sp_train.pkl  \n",
      " extracting: ./data/superpixels/mnist_75sp_test.pkl  \n",
      " extracting: ./data/superpixels/mnist_75sp_train.pkl  \n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('superpixels.zip'):\n",
    "    print('downloading..')\n",
    "    from gli.utils import _download\n",
    "    _download(\"https://www.dropbox.com/s/y2qwa77a0fxem47/superpixels.zip?dl=1\", \"superpixels.zip\", verbose=True)\n",
    "    !mkdir -p data\n",
    "    !unzip superpixels.zip -d ./data/\n",
    "    # !tar -xvf superpixels.zip -C ../\n",
    "else:\n",
    "    print('File already downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/graphdeeplearning/benchmarking-gnns/blob/master/data/superpixels.py\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import time\n",
    "\n",
    "import csv\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sigma(dists, kth=8):\n",
    "    # Compute sigma and reshape\n",
    "    try:\n",
    "        # Get k-nearest neighbors for each node\n",
    "        knns = np.partition(dists, kth, axis=-1)[:, kth::-1]\n",
    "        sigma = knns.sum(axis=1).reshape((knns.shape[0], 1))/kth\n",
    "    except ValueError:     # handling for graphs with num_nodes less than kth\n",
    "        num_nodes = dists.shape[0]\n",
    "        # this sigma value is irrelevant since not used for final compute_edge_list\n",
    "        sigma = np.array([1]*num_nodes).reshape(num_nodes,1)\n",
    "        \n",
    "    return sigma + 1e-8 # adding epsilon to avoid zero value of sigma\n",
    "\n",
    "\n",
    "def compute_adjacency_matrix_images(coord, feat, use_feat=True, kth=8):\n",
    "    coord = coord.reshape(-1, 2)\n",
    "    # Compute coordinate distance\n",
    "    c_dist = cdist(coord, coord)\n",
    "    \n",
    "    if use_feat:\n",
    "        # Compute feature distance\n",
    "        f_dist = cdist(feat, feat)\n",
    "        # Compute adjacency\n",
    "        A = np.exp(- (c_dist/sigma(c_dist))**2 - (f_dist/sigma(f_dist))**2 )\n",
    "    else:\n",
    "        A = np.exp(- (c_dist/sigma(c_dist))**2)\n",
    "        \n",
    "    # Convert to symmetric matrix\n",
    "    A = 0.5 * (A + A.T)\n",
    "    A[np.diag_indices_from(A)] = 0\n",
    "    return A        \n",
    "\n",
    "\n",
    "def compute_edges_list(A, kth=8+1):\n",
    "    # Get k-similar neighbor indices for each node\n",
    "\n",
    "    num_nodes = A.shape[0]\n",
    "    new_kth = num_nodes - kth\n",
    "    \n",
    "    if num_nodes > 9:\n",
    "        knns = np.argpartition(A, new_kth-1, axis=-1)[:, new_kth:-1]\n",
    "        knn_values = np.partition(A, new_kth-1, axis=-1)[:, new_kth:-1] # NEW\n",
    "    else:\n",
    "        # handling for graphs with less than kth nodes\n",
    "        # in such cases, the resulting graph will be fully connected\n",
    "        knns = np.tile(np.arange(num_nodes), num_nodes).reshape(num_nodes, num_nodes)\n",
    "        knn_values = A # NEW\n",
    "        \n",
    "        # removing self loop\n",
    "        if num_nodes != 1:\n",
    "            knn_values = A[knns != np.arange(num_nodes)[:,None]].reshape(num_nodes,-1) # NEW\n",
    "            knns = knns[knns != np.arange(num_nodes)[:,None]].reshape(num_nodes,-1)\n",
    "    return knns, knn_values # NEW\n",
    "\n",
    "\n",
    "class SuperPixDGL(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 data_dir,\n",
    "                 dataset,\n",
    "                 split,\n",
    "                 use_mean_px=True,\n",
    "                 use_coord=True):\n",
    "\n",
    "        self.split = split\n",
    "        \n",
    "        self.graph_lists = []\n",
    "        \n",
    "        if dataset == 'MNIST':\n",
    "            self.img_size = 28\n",
    "            with open(os.path.join(data_dir, 'mnist_75sp_%s.pkl' % split), 'rb') as f:\n",
    "                self.labels, self.sp_data = pickle.load(f)\n",
    "                self.graph_labels = torch.LongTensor(self.labels)\n",
    "        elif dataset == 'CIFAR10':\n",
    "            self.img_size = 32\n",
    "            with open(os.path.join(data_dir, 'cifar10_150sp_%s.pkl' % split), 'rb') as f:\n",
    "                self.labels, self.sp_data = pickle.load(f)\n",
    "                self.graph_labels = torch.LongTensor(self.labels)\n",
    "                \n",
    "        self.use_mean_px = use_mean_px\n",
    "        self.use_coord = use_coord\n",
    "        self.n_samples = len(self.labels)\n",
    "        \n",
    "        self._prepare()\n",
    "    \n",
    "    def _prepare(self):\n",
    "        print(\"preparing %d graphs for the %s set...\" % (self.n_samples, self.split.upper()))\n",
    "        self.Adj_matrices, self.node_features, self.edges_lists, self.edge_features = [], [], [], []\n",
    "        for index, sample in enumerate(self.sp_data):\n",
    "            mean_px, coord = sample[:2]\n",
    "            \n",
    "            try:\n",
    "                coord = coord / self.img_size\n",
    "            except AttributeError:\n",
    "                VOC_has_variable_image_sizes = True\n",
    "                \n",
    "            if self.use_mean_px:\n",
    "                A = compute_adjacency_matrix_images(coord, mean_px) # using super-pixel locations + features\n",
    "            else:\n",
    "                A = compute_adjacency_matrix_images(coord, mean_px, False) # using only super-pixel locations\n",
    "            edges_list, edge_values_list = compute_edges_list(A) # NEW\n",
    "\n",
    "            N_nodes = A.shape[0]\n",
    "            \n",
    "            mean_px = mean_px.reshape(N_nodes, -1)\n",
    "            coord = coord.reshape(N_nodes, 2)\n",
    "            x = np.concatenate((mean_px, coord), axis=1)\n",
    "\n",
    "            edge_values_list = edge_values_list.reshape(-1) # NEW # TO DOUBLE-CHECK !\n",
    "            \n",
    "            self.node_features.append(x)\n",
    "            self.edge_features.append(edge_values_list) # NEW\n",
    "            self.Adj_matrices.append(A)\n",
    "            self.edges_lists.append(edges_list)\n",
    "        \n",
    "        for index in range(len(self.sp_data)):\n",
    "            g = dgl.DGLGraph()\n",
    "            g.add_nodes(self.node_features[index].shape[0])\n",
    "            g.ndata['feat'] = torch.Tensor(self.node_features[index]).half() \n",
    "\n",
    "            for src, dsts in enumerate(self.edges_lists[index]):\n",
    "                # handling for 1 node where the self loop would be the only edge\n",
    "                # since, VOC Superpixels has few samples (5 samples) with only 1 node\n",
    "                if self.node_features[index].shape[0] == 1:\n",
    "                    g.add_edges(src, dsts)\n",
    "                else:\n",
    "                    g.add_edges(src, dsts[dsts!=src])\n",
    "            \n",
    "            # adding edge features for Residual Gated ConvNet\n",
    "            edge_feat_dim = g.ndata['feat'].shape[1] # dim same as node feature dim\n",
    "            #g.edata['feat'] = torch.ones(g.number_of_edges(), edge_feat_dim).half() \n",
    "            g.edata['feat'] = torch.Tensor(self.edge_features[index]).unsqueeze(1).half()  # NEW \n",
    "\n",
    "            self.graph_lists.append(g)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of graphs in the dataset.\"\"\"\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "            Get the idx^th sample.\n",
    "            Parameters\n",
    "            ---------\n",
    "            idx : int\n",
    "                The sample index.\n",
    "            Returns\n",
    "            -------\n",
    "            (dgl.DGLGraph, int)\n",
    "                DGLGraph with node feature stored in `feat` field\n",
    "                And its label.\n",
    "        \"\"\"\n",
    "        return self.graph_lists[idx], self.graph_labels[idx]\n",
    "\n",
    "\n",
    "class DGLFormDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        DGLFormDataset wrapping graph list and label list as per pytorch Dataset.\n",
    "        *lists (list): lists of 'graphs' and 'labels' with same len().\n",
    "    \"\"\"\n",
    "    def __init__(self, *lists):\n",
    "        assert all(len(lists[0]) == len(li) for li in lists)\n",
    "        self.lists = lists\n",
    "        self.graph_lists = lists[0]\n",
    "        self.graph_labels = lists[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return tuple(li[index] for li in self.lists)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lists[0])\n",
    "    \n",
    "    \n",
    "class SuperPixDatasetDGL(torch.utils.data.Dataset):\n",
    "    def __init__(self, name, num_val=5000):\n",
    "        \"\"\"\n",
    "            Takes input standard image dataset name (MNIST/CIFAR10) \n",
    "            and returns the superpixels graph.\n",
    "            \n",
    "            This class uses results from the above SuperPix class.\n",
    "            which contains the steps for the generation of the Superpixels\n",
    "            graph from a superpixel .pkl file that has been given by\n",
    "            https://github.com/bknyaz/graph_attention_pool\n",
    "            \n",
    "            Please refer the SuperPix class for details.\n",
    "        \"\"\"\n",
    "        t_data = time.time()\n",
    "        self.name = name\n",
    "\n",
    "        use_mean_px = True # using super-pixel locations + features\n",
    "        use_mean_px = False # using only super-pixel locations\n",
    "        if use_mean_px:\n",
    "            print('Adj matrix defined from super-pixel locations + features')\n",
    "        else:\n",
    "            print('Adj matrix defined from super-pixel locations (only)')\n",
    "        use_coord = True\n",
    "        self.test = SuperPixDGL(\"./data/superpixels\", dataset=self.name, split='test', \n",
    "                            use_mean_px=use_mean_px, \n",
    "                            use_coord=use_coord)\n",
    "\n",
    "        self.train_ = SuperPixDGL(\"./data/superpixels\", dataset=self.name, split='train', \n",
    "                             use_mean_px=use_mean_px, \n",
    "                             use_coord=use_coord)\n",
    "\n",
    "        _val_graphs, _val_labels = self.train_[:num_val]\n",
    "        _train_graphs, _train_labels = self.train_[num_val:]\n",
    "\n",
    "        self.val = DGLFormDataset(_val_graphs, _val_labels)\n",
    "        self.train = DGLFormDataset(_train_graphs, _train_labels)\n",
    "\n",
    "        print(\"[I] Data load time: {:.4f}s\".format(time.time()-t_data))\n",
    "        \n",
    "\n",
    "\n",
    "def self_loop(g):\n",
    "    \"\"\"\n",
    "        Utility function only, to be used only when necessary as per user self_loop flag\n",
    "        : Overwriting the function dgl.transform.add_self_loop() to not miss ndata['feat'] and edata['feat']\n",
    "        \n",
    "        \n",
    "        This function is called inside a function in SuperPixDataset class.\n",
    "    \"\"\"\n",
    "    new_g = dgl.DGLGraph()\n",
    "    new_g.add_nodes(g.number_of_nodes())\n",
    "    new_g.ndata['feat'] = g.ndata['feat']\n",
    "    \n",
    "    src, dst = g.all_edges(order=\"eid\")\n",
    "    src = dgl.backend.zerocopy_to_numpy(src)\n",
    "    dst = dgl.backend.zerocopy_to_numpy(dst)\n",
    "    non_self_edges_idx = src != dst\n",
    "    nodes = np.arange(g.number_of_nodes())\n",
    "    new_g.add_edges(src[non_self_edges_idx], dst[non_self_edges_idx])\n",
    "    new_g.add_edges(nodes, nodes)\n",
    "    \n",
    "    # This new edata is not used since this function gets called only for GCN, GAT\n",
    "    # However, we need this for the generic requirement of ndata and edata\n",
    "    new_g.edata['feat'] = torch.zeros(new_g.number_of_edges())\n",
    "    return new_g\n",
    "\n",
    "    \n",
    "\n",
    "class SuperPixDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "            Loading Superpixels datasets\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        print(\"[I] Loading dataset %s...\" % (name))\n",
    "        self.name = name\n",
    "        data_dir = 'data/superpixels/'\n",
    "        with open(data_dir+name+'.pkl',\"rb\") as f:\n",
    "            f = pickle.load(f)\n",
    "            self.train = f[0]\n",
    "            self.val = f[1]\n",
    "            self.test = f[2]\n",
    "        print('train, test, val sizes :',len(self.train),len(self.test),len(self.val))\n",
    "        print(\"[I] Finished loading.\")\n",
    "        print(\"[I] Data load time: {:.4f}s\".format(time.time()-start))\n",
    "\n",
    "\n",
    "    # form a mini batch from a given list of samples = [(graph, label) pairs]\n",
    "    def collate(self, samples):\n",
    "        # The input samples is a list of pairs (graph, label).\n",
    "        graphs, labels = map(list, zip(*samples))\n",
    "        labels = torch.tensor(np.array(labels))\n",
    "        #tab_sizes_n = [ graphs[i].number_of_nodes() for i in range(len(graphs))]\n",
    "        #tab_snorm_n = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_n ]\n",
    "        #snorm_n = torch.cat(tab_snorm_n).sqrt()  \n",
    "        #tab_sizes_e = [ graphs[i].number_of_edges() for i in range(len(graphs))]\n",
    "        #tab_snorm_e = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_e ]\n",
    "        #snorm_e = torch.cat(tab_snorm_e).sqrt()\n",
    "        for idx, graph in enumerate(graphs):\n",
    "            graphs[idx].ndata['feat'] = graph.ndata['feat'].float()\n",
    "            graphs[idx].edata['feat'] = graph.edata['feat'].float()\n",
    "        batched_graph = dgl.batch(graphs)\n",
    "        \n",
    "        return batched_graph, labels\n",
    "    \n",
    "    \n",
    "    # prepare dense tensors for GNNs using them; such as RingGNN, 3WLGNN\n",
    "    def collate_dense_gnn(self, samples):\n",
    "        # The input samples is a list of pairs (graph, label).\n",
    "        graphs, labels = map(list, zip(*samples))\n",
    "        labels = torch.tensor(np.array(labels))\n",
    "        #tab_sizes_n = [ graphs[i].number_of_nodes() for i in range(len(graphs))]\n",
    "        #tab_snorm_n = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_n ]\n",
    "        #snorm_n = tab_snorm_n[0][0].sqrt()  \n",
    "        \n",
    "        #batched_graph = dgl.batch(graphs)\n",
    "    \n",
    "        g = graphs[0]\n",
    "        adj = self._sym_normalize_adj(g.adjacency_matrix().to_dense())        \n",
    "        \"\"\"\n",
    "            Adapted from https://github.com/leichen2018/Ring-GNN/\n",
    "            Assigning node and edge feats::\n",
    "            we have the adjacency matrix in R^{n x n}, the node features in R^{d_n} and edge features R^{d_e}.\n",
    "            Then we build a zero-initialized tensor, say T, in R^{(1 + d_n + d_e) x n x n}. T[0, :, :] is the adjacency matrix.\n",
    "            The diagonal T[1:1+d_n, i, i], i = 0 to n-1, store the node feature of node i. \n",
    "            The off diagonal T[1+d_n:, i, j] store edge features of edge(i, j).\n",
    "        \"\"\"\n",
    "\n",
    "        zero_adj = torch.zeros_like(adj)\n",
    "        \n",
    "        in_dim = g.ndata['feat'].shape[1]\n",
    "        \n",
    "        # use node feats to prepare adj\n",
    "        adj_node_feat = torch.stack([zero_adj for j in range(in_dim)])\n",
    "        adj_node_feat = torch.cat([adj.unsqueeze(0), adj_node_feat], dim=0)\n",
    "        \n",
    "        for node, node_feat in enumerate(g.ndata['feat']):\n",
    "            adj_node_feat[1:, node, node] = node_feat\n",
    "\n",
    "        x_node_feat = adj_node_feat.unsqueeze(0)\n",
    "        \n",
    "        return x_node_feat, labels\n",
    "    \n",
    "    def _sym_normalize_adj(self, adj):\n",
    "        deg = torch.sum(adj, dim = 0)#.squeeze()\n",
    "        deg_inv = torch.where(deg>0, 1./torch.sqrt(deg), torch.zeros(deg.size()))\n",
    "        deg_inv = torch.diag(deg_inv)\n",
    "        return torch.mm(deg_inv, torch.mm(adj, deg_inv))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _add_self_loops(self):\n",
    "        \n",
    "        # function for adding self loops\n",
    "        # this function will be called only if self_loop flag is True\n",
    "            \n",
    "        self.train.graph_lists = [self_loop(g) for g in self.train.graph_lists]\n",
    "        self.val.graph_lists = [self_loop(g) for g in self.val.graph_lists]\n",
    "        self.test.graph_lists = [self_loop(g) for g in self.test.graph_lists]\n",
    "        \n",
    "        self.train = DGLFormDataset(self.train.graph_lists, self.train.graph_labels)\n",
    "        self.val = DGLFormDataset(self.val.graph_lists, self.val.graph_labels)\n",
    "        self.test = DGLFormDataset(self.test.graph_lists, self.test.graph_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj matrix defined from super-pixel locations (only)\n",
      "preparing 10000 graphs for the TEST set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/GLI/lib/python3.6/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing 50000 graphs for the TRAIN set...\n",
      "[I] Data load time: 2246.7163s\n",
      "Time (sec): 2246.720936059952\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "DATASET_NAME = 'CIFAR10'\n",
    "dataset = SuperPixDatasetDGL(DATASET_NAME) \n",
    "\n",
    "print('Time (sec):',time.time() - start) # 636s=10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n",
      "5000\n",
      "10000\n",
      "(Graph(num_nodes=110, num_edges=880,\n",
      "      ndata_schemes={'feat': Scheme(shape=(5,), dtype=torch.float16)}\n",
      "      edata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float16)}), tensor(6))\n",
      "(Graph(num_nodes=123, num_edges=984,\n",
      "      ndata_schemes={'feat': Scheme(shape=(5,), dtype=torch.float16)}\n",
      "      edata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float16)}), tensor(6))\n",
      "(Graph(num_nodes=118, num_edges=944,\n",
      "      ndata_schemes={'feat': Scheme(shape=(5,), dtype=torch.float16)}\n",
      "      edata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float16)}), tensor(3))\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.train))\n",
    "print(len(dataset.val))\n",
    "print(len(dataset.test))\n",
    "\n",
    "print(dataset.train[0])\n",
    "print(dataset.val[0])\n",
    "print(dataset.test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx=np.arange(0,45000,1)\n",
    "valid_idx=np.arange(45000,50000,1)\n",
    "test_idx=np.arange(50000,60000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save all dense arrays to cifar_task.npz, including ['train', 'val', 'test']\n"
     ]
    }
   ],
   "source": [
    "task_data = {\n",
    "    \"train\": train_idx,\n",
    "    \"val\": valid_idx,\n",
    "    \"test\": test_idx\n",
    "}\n",
    "\n",
    "from gli.utils import save_data\n",
    "save_data(\"cifar_task\", **task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45000/45000 [00:21<00:00, 2104.71it/s]\n",
      "100%|██████████| 5000/5000 [00:03<00:00, 1613.89it/s]\n",
      "100%|██████████| 10000/10000 [00:04<00:00, 2386.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "node_list = []\n",
    "labels = []\n",
    "edges = []\n",
    "edge_feats = []\n",
    "node_feats = []\n",
    "num_nodes = 0\n",
    "for g, label in tqdm(dataset.train):\n",
    "    node_list.append(np.arange(g.num_nodes()) + num_nodes)  # All the nodes are considered in a single graph\n",
    "    \n",
    "    labels.append(label)\n",
    "    edges.append(np.stack([g.edges()[0],g.edges()[1]]).T + num_nodes)\n",
    "    edge_feats.append(np.array(g.edata['feat']))\n",
    "    node_feats.append(np.array(g.ndata['feat']))\n",
    "    num_nodes += g.num_nodes()\n",
    "for g, label in tqdm(dataset.val):\n",
    "    node_list.append(np.arange(g.num_nodes()) + num_nodes)  # All the nodes are considered in a single graph\n",
    "    labels.append(label)\n",
    "    edges.append(np.stack([g.edges()[0],g.edges()[1]]).T + num_nodes)\n",
    "    edge_feats.append(np.array(g.edata['feat']))\n",
    "    node_feats.append(np.array(g.ndata['feat']))\n",
    "    num_nodes += g.num_nodes()\n",
    "for g, label in tqdm(dataset.test):\n",
    "    node_list.append(np.arange(g.num_nodes()) + num_nodes)  # All the nodes are considered in a single graph\n",
    "\n",
    "\n",
    "    labels.append(label)\n",
    "    edges.append(np.stack([g.edges()[0],g.edges()[1]]).T + num_nodes)\n",
    "    edge_feats.append(np.array(g.edata['feat']))\n",
    "    node_feats.append(np.array(g.ndata['feat']))\n",
    "    num_nodes += g.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_edges = np.concatenate(edges, axis=0)\n",
    "_labels = np.stack(labels).squeeze()\n",
    "_edge_feats = np.concatenate(edge_feats)\n",
    "_node_feats = np.concatenate(node_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "_node_list = sparse.lil_matrix((60000, num_nodes))\n",
    "\n",
    "for i, indices in enumerate(node_list):\n",
    "    _node_list[i, indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"node_feats\": _node_feats,\n",
    "    \"graph_class\": _labels,\n",
    "    \"edge\": _edges,\n",
    "    \"edge_feats\": _edge_feats,\n",
    "    \"node_list\": _node_list.tocsr(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save all dense arrays to cifar.npz, including ['node_feats', 'graph_class', 'edge', 'edge_feats']\n",
      "Save sparse matrix node_list to cifar_node_list.sparse.npz\n"
     ]
    }
   ],
   "source": [
    "from gli.utils import save_data\n",
    "save_data(\"cifar\", **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GLI",
   "language": "python",
   "name": "gli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
