name: Pytest

on: [workflow_dispatch, pull_request_target]

permissions:
      # id-token: write
      # contents: write
      # security-events: write
      pull-requests: write

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.6"]
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest
        pip install -e .
        pip install pyyaml
    - name: Get changed files using defaults
      id: changed-files
      uses: tj-actions/changed-files@v23.1
    - name: List all changed files
      run: |
        for file in ${{ steps.changed-files.outputs.all_changed_and_modified_files }}; do
          echo "$file was changed"
        done
    - name: Test with pytest, if triggered by PR
      run: |
        if ${{ github.event_name == 'pull_request_target' }}
        then
          dataset_list=()
          for path in ${{ steps.changed-files.outputs.all_changed_and_modified_files }}; do
              dir="$(dirname "${path}")" ;
              if [ ! -d "$dir" ]; then
                echo "$dir doesn't exist, continue"
                continue;
              fi
              dataset=$(echo $path | grep "datasets" | sed -r 's/datasets\/([_a-zA-Z0-9-]+)\/.*/\1/')
              if [ -z "$dataset" ]; then continue; fi
              if [[ ! " ${dataset_list[*]} " =~ " ${dataset} " ]]; then
                echo "add dataset: $dataset"
                dataset_list+=($dataset)
              fi
          done
          echo "datasets list is ${dataset_list[*]}"
          mkdir temp
          echo "${dataset_list[*]}" > temp/changed_datasets
          python tests/preprocess.py
          pytest tests/
        fi
    - name: Check large datasets
      id: main
      run: |
        echo "$dataset_list[*]"
        dataset_list=()
        for path in ${{ steps.changed-files.outputs.all_changed_and_modified_files }}; do
            dir="$(dirname "${path}")" ;
            if [ ! -d "$dir" ]; then
              echo "$dir doesn't exist, continue"
              continue;
            fi
            dataset=$(echo $path | grep "datasets" | sed -r 's/datasets\/([_a-zA-Z0-9-]+)\/.*/\1/')
            if [ -z "$dataset" ]; then continue; fi
            if [[ ! " ${dataset_list[*]} " =~ " ${dataset} " ]]; then
              echo "add dataset: $dataset"
              dataset_list+=($dataset)
            fi
        done
        echo "$dataset_list[*]"
        dataset_to_comment=()
        large_dataset_list=$(cat tests/config.yaml | sed -r 's/large_dataset_to_skip: \[(.*)\]/\1/')
        for dataset in "${dataset_list[@]}"; do
          if [[  "$large_dataset_list" == *"$dataset"* ]]; then
            echo "add ${dataset} to dataset_to_comment"
            dataset_to_comment+=($dataset)
          fi
        done
        COMMENT=0
        if [ ${#dataset_to_comment[@]} -ne 0 ]; then
          echo "dataset to be commented are: ${dataset_to_comment[*]}"
          COMMENT=1
        fi
        echo "::set-output name=OUTPUT::$COMMENT"
        echo "::set-output name=DATASETS::${dataset_to_comment[*]}"
    - name: Comment PR
      if: ${{ github.event_name == 'pull_request_target' && steps.main.outputs.OUTPUT == 1 }}
      uses: peter-evans/create-or-update-comment@v2
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          github.issues.createComment({
            issue_number: ${{ github.event.number }},
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: 'This is an automatic reminder for pasting the local test results of `${{ steps.main.outputs.DATASETS }}` as a comment in this PR, in case you haven't done so. 
                   The aforementioned datasets are too large for them to be tested with GitHub Action workflow here.
                   The local test result for each dataset can be obtained by running `make pytest DATASET=<dataset name>`. 
                   For more details, please refer to [the dataset submission guide](https://github.com/Graph-Learning-Benchmarks/gli/blob/main/CONTRIBUTING.md#contributing-a-new-dataset).'
          })
    - name: Test all datasets with pytest, if triggered by workflow_dispatch
      run: |
        if ${{ github.event_name == 'workflow_dispatch' }}
        then
          python tests/preprocess.py
          pytest tests/
        fi
